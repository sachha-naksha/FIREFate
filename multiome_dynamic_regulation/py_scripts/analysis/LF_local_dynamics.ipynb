{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import dictys\n",
    "from dictys.net import stat\n",
    "import joblib\n",
    "import pickle\n",
    "from scipy.stats import median_abs_deviation, hypergeom\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_custom import *\n",
    "from episodic_dynamics import *\n",
    "from pseudotime_curves import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "dictys_dynamic_object_path = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/dynamic.h5\"\n",
    "output_folder = '/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/blimp1_ko/gc_98'\n",
    "latent_factor_folder = '/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/other_files/latent_factors'\n",
    "lf_blimp1_file = f\"{latent_factor_folder}/feature_list_Z5_PRDM1_KO.txt\"\n",
    "lf_irf4_file = f\"{latent_factor_folder}/feature_list_Z4_IRF4_KO.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_blimp1 = pd.read_csv(lf_blimp1_file, sep='\\t')['names'].tolist()\n",
    "lf_irf4 = pd.read_csv(lf_irf4_file, sep='\\t')['names'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_episode(\n",
    "    episode_idx=4,\n",
    "    dictys_dynamic_object_path=dictys_dynamic_object_path,\n",
    "    output_folder=output_folder,\n",
    "    latent_factor_folder=latent_factor_folder,\n",
    "    trajectory_range=(1, 3),\n",
    "    num_points=40,\n",
    "    time_slice_start=15,\n",
    "    time_slice_end=20, # last index is excluded\n",
    "    lf_genes=lf_blimp1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un-parallelized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dictys_dynamic_object = dictys.net.dynamic_network.from_file(dictys_dynamic_object_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expression dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lcpm chars for these genes\n",
    "lcpm_dcurve, dtime = compute_expression_regulation_curves(dictys_dynamic_object, start=1, stop=3, num=40, dist=0.001, mode=\"expression\")\n",
    "# remove genes with names starting with ZNF and ZBTB\n",
    "lcpm_dcurve = lcpm_dcurve[~lcpm_dcurve.index.str.startswith('ZNF') & ~lcpm_dcurve.index.str.startswith('ZBTB')]\n",
    "# get lcpm chars for these genes\n",
    "#lcpm_dcurve_gc, dtime_gc = compute_expression_regulation_curves(dictys_dynamic_object, start=0, stop=3, num=20, dist=0.001, mode=\"expression\")\n",
    "# slice the dcurve for the lf genes using gene names which are indices in pandas df\n",
    "display(lcpm_dcurve.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regulation dynamics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts, fsmooth = dictys_dynamic_object.linspace(1,3,40,0.001)\n",
    "stat1_net = fsmooth(stat.net(dictys_dynamic_object)) #varname=w_in loads total effect network\n",
    "stat1_netbin = stat.fbinarize(stat1_net,sparsity=0.01)\n",
    "stat1_x=stat.pseudotime(dictys_dynamic_object,pts)\n",
    "dtime = pd.Series(stat1_x.compute(pts)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get episode specific GRN (transient state specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pts is a dictys traj object\n",
    "dnetbin = stat1_netbin.compute(pts)\n",
    "dnetbin_episode = dnetbin[:, :, 0:5] #5 timepoints, excludes the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the weighted network\n",
    "dnet = stat1_net.compute(pts)\n",
    "dnet_episode = dnet[:, :, 0:5]\n",
    "display(dnet_episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter episodic GRN edges which are significantly non-zero across time points and are direction invariant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Get the tf and target names #####\n",
    "# Create reverse mapping: index -> gene_name\n",
    "ndict = dictys_dynamic_object.ndict\n",
    "index_to_gene = {idx: name for name, idx in ndict.items()}\n",
    "target_names = [index_to_gene[idx] for idx in range(dnetbin_episode.shape[1])]\n",
    "# Get TF_gene_indices from TFs_to_keep_indices using nids[0]\n",
    "tf_gene_indices = [dictys_dynamic_object.nids[0][tf_idx] for tf_idx in range(dnetbin_episode.shape[0])]\n",
    "tf_names = [index_to_gene[idx] for idx in tf_gene_indices]\n",
    "print(len(target_names))\n",
    "print(len(tf_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Create multi-index tuples (all combinations of TF-target pairs) ######\n",
    "index_tuples = [(tf, target) for tf in tf_names for target in target_names]\n",
    "multi_index = pd.MultiIndex.from_tuples(index_tuples, names=['TF', 'Target'])\n",
    "# Reshape the subnetworks array to 2D (pairs Ã— time points)\n",
    "n_tfs, n_targets, n_times = dnet_episode.shape\n",
    "reshaped_data = dnet_episode.reshape(-1, n_times)\n",
    "# Create DataFrame with multi-index\n",
    "episode_beta_dcurve = pd.DataFrame(\n",
    "    reshaped_data,\n",
    "    index=multi_index,\n",
    "    columns=[f'time_{i}' for i in range(n_times)]\n",
    ")\n",
    "# drop rows that are all 0\n",
    "episode_beta_dcurve = episode_beta_dcurve[episode_beta_dcurve.sum(axis=1) != 0]\n",
    "# the number of edges here remain the same between episodes, indicating that exact 0 are the edges that don't have atac-seq basis\n",
    "display(episode_beta_dcurve.head())\n",
    "display(episode_beta_dcurve.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Filtering the global episodic GRN for retaining significantly non-zero and direction invariant edges ######\n",
    "filtered_edges = filter_edges_by_significance_and_direction(\n",
    "    episode_beta_dcurve,\n",
    "    min_nonzero_timepoints=3,\n",
    "    alpha=0.05,\n",
    "    min_observations=3,\n",
    "    check_direction_invariance=True,  # Enable direction invariance check\n",
    "    n_processes=60,\n",
    "    chunk_size=8000,\n",
    "    save_intermediate=False,\n",
    "    intermediate_path=output_folder\n",
    ")\n",
    "    \n",
    "print(f\"\\nFinal shape: {filtered_edges.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load episode parquet file into pandas\n",
    "#filtered_edges = pd.read_parquet('/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/filtered_edges_significant_invariant_PB_ep4.parquet')\n",
    "# remove TFs starting with ZNF or ZBTB\n",
    "filtered_edges = filtered_edges[~filtered_edges.index.get_level_values(0).str.startswith('ZNF') & ~filtered_edges.index.get_level_values(0).str.startswith('ZBTB')]\n",
    "display(filtered_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop edges with p_value > 0.01\n",
    "filtered_edges_p001 = filtered_edges[filtered_edges['p_value'] < 0.001]\n",
    "display(filtered_edges_p001.head())\n",
    "display(filtered_edges_p001.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get TF forces for the episode & State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### CHANGE STATE HERE ######\n",
    "tf_lcpm_values = lcpm_dcurve.loc[filtered_edges_p001.index.get_level_values(0).unique()]\n",
    "display(tf_lcpm_values.shape)\n",
    "###### CHANGE EPISODE HERE ######\n",
    "tf_lcpm_episode = tf_lcpm_values.iloc[:, 15:20]\n",
    "\n",
    "# Adaptive column renaming to match beta curves\n",
    "beta_time_cols = [col for col in filtered_edges_p001.columns if col.startswith('time_')]\n",
    "n_time_cols = len(beta_time_cols)\n",
    "\n",
    "# Rename TF expression columns to match beta curves format\n",
    "tf_lcpm_episode.columns = beta_time_cols[:n_time_cols]\n",
    "display(tf_lcpm_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare beta curves (only time columns)\n",
    "beta_curves_for_force = filtered_edges_p001.drop('p_value', axis=1)\n",
    "\n",
    "print(\"Starting parallel force calculation...\")\n",
    "print(f\"Input beta curves shape: {beta_curves_for_force.shape}\")\n",
    "print(f\"TF expression shape: {tf_lcpm_episode.shape}\")\n",
    "\n",
    "# Calculate forces in parallel\n",
    "force_curves = calculate_force_curves_parallel(\n",
    "    beta_curves=beta_curves_for_force,\n",
    "    tf_expression=tf_lcpm_episode,\n",
    "    n_processes=20,  # Adjust based on your system\n",
    "    chunk_size=30000,  # Adjust based on available memory\n",
    "    epsilon=1e-10,\n",
    "    save_intermediate=False\n",
    ")\n",
    "\n",
    "print(f\"Force calculation completed!\")\n",
    "print(f\"Output shape: {force_curves.shape}\")\n",
    "# Display sample results\n",
    "display(force_curves.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the average force over the episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average force over the 5 time points\n",
    "avg_force = force_curves.mean(axis=1)\n",
    "print(f\"Average force shape: {avg_force.shape}\")\n",
    "# Convert to DataFrame with proper column name\n",
    "avg_force_df = avg_force.to_frame(name='avg_force')\n",
    "display(avg_force_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution\n",
    "fig, axes = plt.subplots(1, 1, figsize=(15, 6))\n",
    "\n",
    "# Separate positive and negative forces\n",
    "positive_forces = avg_force[avg_force > 0]\n",
    "negative_forces = avg_force[avg_force < 0]\n",
    "\n",
    "axes.hist([positive_forces, negative_forces], bins=50, alpha=0.7, \n",
    "              color=['red', 'blue'], label=['Positive Forces', 'Negative Forces'], edgecolor='black')\n",
    "axes.set_xlabel('Average Force')\n",
    "axes.set_ylabel('Number of Edges')\n",
    "axes.set_title('Distribution by Force Direction')\n",
    "axes.legend()\n",
    "axes.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "if len(positive_forces) > 0:\n",
    "    pos_threshold = np.percentile(positive_forces, 98)\n",
    "    top_pos_edges = positive_forces[positive_forces >= pos_threshold]\n",
    "else:\n",
    "    top_pos_edges = pd.Series(dtype=avg_force.dtype)\n",
    "\n",
    "if len(negative_forces) > 0:\n",
    "    neg_threshold = np.percentile(negative_forces, 0.5)\n",
    "    top_neg_edges = negative_forces[negative_forces <= neg_threshold]\n",
    "else:\n",
    "    top_neg_edges = pd.Series(dtype=avg_force.dtype)\n",
    "\n",
    "# Combine into a DataFrame\n",
    "episodic_grn_edges = pd.concat([top_pos_edges, top_neg_edges]).to_frame(name='avg_force')\n",
    "\n",
    "# Optionally, sort by force value (descending for positive, ascending for negative)\n",
    "episodic_grn_edges = episodic_grn_edges.sort_values(by='avg_force', ascending=False)\n",
    "\n",
    "# Display or use as needed\n",
    "print(episodic_grn_edges)\n",
    "print(f\"Number of positive edges: {len(top_pos_edges)}\")\n",
    "print(f\"Number of negative edges: {len(top_neg_edges)}\")\n",
    "print(f\"Total selected edges: {len(episodic_grn_edges)}\")\n",
    "# display the unique tf and target numbers\n",
    "display(len(episodic_grn_edges.index.get_level_values(0).unique()))\n",
    "display(len(episodic_grn_edges.index.get_level_values(1).unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the top k% of edges to build the episodic GRN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the TFs acting on LF genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load LF files \n",
    "z11_file = '/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/other_files/latent_factors/feature_list_Z11_GC_PB.txt'\n",
    "z3_file = '/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/other_files/latent_factors/feature_list_Z3_GC_PB.txt'\n",
    "z_prdm1_ko = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/other_files/latent_factors/feature_list_Z5_PRDM1_KO.txt\"\n",
    "# load into a list of gene names \n",
    "z11 = pd.read_csv(z11_file, sep='\\t', header=0)\n",
    "z3 = pd.read_csv(z3_file, sep='\\t', header=0)\n",
    "z_prdm1_ko = pd.read_csv(z_prdm1_ko, sep='\\t', header=0)\n",
    "# remove HLA- genes\n",
    "z11 = z11[~z11['names'].str.contains('HLA-')]\n",
    "z3 = z3[~z3['names'].str.contains('HLA-')]\n",
    "z_prdm1_ko = z_prdm1_ko[~z_prdm1_ko['names'].str.contains('HLA-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the gene names \n",
    "z11_genes = z11['names'].tolist()\n",
    "z3_genes = z3['names'].tolist()\n",
    "z_prdm1_ko_genes = z_prdm1_ko['names'].tolist()\n",
    "# create a list of all lf genes \n",
    "#lf_genes = list(set(z11_genes + z3_genes))\n",
    "lf_genes = list(set(z_prdm1_ko_genes))\n",
    "lf_in_object = check_if_gene_in_ndict(dictys_dynamic_object, lf_genes, return_index=True)\n",
    "print(f\"Found {len(lf_in_object['present'])} genes\")\n",
    "print(f\"Missing {len(lf_in_object['missing'])} genes\")\n",
    "print(\"Indices:\", lf_in_object['indices'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the enrichment (over representation) of LF genes in TF regulons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a boolean column indicating if the target is a lf gene in the episodic grn df\n",
    "episodic_grn_edges['is_in_lf'] = episodic_grn_edges.index.get_level_values(1).isin(lf_genes)\n",
    "# get the number of genes in the episodic grn edges\n",
    "target_genes_in_episodic_grn = episodic_grn_edges.index.get_level_values(1).unique()\n",
    "display(\"Number of targets in episodic grn: \", len(target_genes_in_episodic_grn))\n",
    "# get the number of lf_genes in the episodic grn edges\n",
    "lf_in_episodic_grn = episodic_grn_edges[episodic_grn_edges['is_in_lf']]\n",
    "display(lf_in_episodic_grn.head())\n",
    "# get the unique LF genes active in the lf_in_episodic_grn df\n",
    "lf_genes_active_in_episode = lf_in_episodic_grn.index.get_level_values(1).unique()\n",
    "display(\"Number of LF genes active in episode: \", len(lf_genes_active_in_episode))\n",
    "tfs_acting_on_lf = lf_in_episodic_grn.index.get_level_values(0).unique()\n",
    "display(\"TFs acting on LF genes: \", tfs_acting_on_lf, len(tfs_acting_on_lf))\n",
    "# take the tfs in the lf_in_episodic_grn df and subset the episodic_grn_edges df to only include these tfs\n",
    "episodic_grn_edges_subset = episodic_grn_edges[episodic_grn_edges.index.get_level_values(0).isin(lf_in_episodic_grn.index.get_level_values(0))]\n",
    "display(episodic_grn_edges_subset.head())\n",
    "display(episodic_grn_edges_subset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodic_enrichment_df = calculate_tf_episodic_enrichment(episodic_grn_edges_subset, \n",
    "                                       len(lf_genes_active_in_episode), \n",
    "                                       len(target_genes_in_episodic_grn))\n",
    "# sort the episodic_enrichment_df_p005 by enrichment_score in descending order\n",
    "episodic_enrichment_df_sorted = episodic_enrichment_df.sort_values(by='enrichment_score', ascending=False)\n",
    "# filter the episodic_enrichment_df to only include tfs with a p_value < threshold\n",
    "episodic_enrichment_df_p005 = episodic_enrichment_df_sorted[episodic_enrichment_df_sorted['p_value'] < 0.05]\n",
    "display(episodic_enrichment_df_p005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the episodic_enrichment_df_p005_sorted df to a csv file\n",
    "episodic_enrichment_df_sorted.to_csv(os.path.join(output_folder, 'enrichment_ep1_blimp_ko.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dictys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
