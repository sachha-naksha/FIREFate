{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, gimmemotifs, pandas as pd, numpy as np, re, os\n",
    "from gimmemotifs.motif import default_motifs\n",
    "wd = '/ocean/projects/cis240075p/skeshari/igvf/bcell2/male_donor/'\n",
    "out_path = os.path.join(wd, 'out_data', 'cicero_lf_enrich')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {\n",
    "    'experiment': ['PRDM1_KO', 'IRF4_KO', 'GC_PB', 'PB_ABC', 'GC_ABC'],\n",
    "    'slide_starting_genes': [4472, 4500, 4725, 3420, 4603],\n",
    "    'clusters_of_interest': [['1','2','3','7'], ['1','2','3','7'], ['7','3'], ['1','7'], ['1','3']],\n",
    "    'order_fr_clust': [[1], [1], [2], [2], [2]],\n",
    "    'order_fr_tfcomb': [[1], [1], [1,2], [2], [2]],\n",
    "    'weight': ['strength', 'strength', 'strength', 'strength', 'strength'],\n",
    "}\n",
    "input_df = pd.DataFrame(input_dict)\n",
    "#### Assign the input parameters\n",
    "i=2\n",
    "experiment = input_df['experiment'][i]\n",
    "slide_starting_genes = input_df['slide_starting_genes'][i]\n",
    "clusters_of_interest = input_df['clusters_of_interest'][i]\n",
    "order_fr_clust = input_df['order_fr_clust'][i]\n",
    "order_fr_tfcomb = input_df['order_fr_tfcomb'][i]\n",
    "weight = input_df['weight'][i]\n",
    "#### Read TFs\n",
    "cluster_fusion = ('7','3')\n",
    "slide_tot_TF = pd.read_csv(f\"{wd}/out_data/lf_enrich/out_files/SLIDE_LF_{cluster_fusion}_{experiment}.csv\", header=0, index_col=0).index.values\n",
    "net_match_TF = pd.read_csv(f\"{wd}/out_data/lf_enrich/out_files/Net_match_{cluster_fusion}_{experiment}.csv\", header=0, index_col=0).index.values\n",
    "net_rnd_TF = pd.read_csv(f\"{wd}/out_data/lf_enrich/out_files/Net_rnd_{cluster_fusion}_{experiment}.csv\", header=0, index_col=0).index.values\n",
    "total_TFs = set(slide_tot_TF).union(set(net_match_TF)).union(set(net_rnd_TF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_TFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_motif2TFs ={}\n",
    "motifs= default_motifs()\n",
    "species = \"Human\"\n",
    "\n",
    "factor_names = ['direct', 'indirect\\nor predicted']\n",
    "\n",
    "for i in motifs:\n",
    "    fcs = []\n",
    "    for j in factor_names:\n",
    "        fcs += i.factors[j]\n",
    "    dict_motif2TFs[i.id] = fcs\n",
    "\n",
    "if species in [\"Mouse\", \"Rat\"]:\n",
    "    for key in dict_motif2TFs.keys():\n",
    "        dict_motif2TFs[key] = [tf.capitalize() for tf in dict_motif2TFs[key]]\n",
    "\n",
    "elif species in [\"Human\", \"S.cerevisiae\", \"Arabidopsis\", \"Axolotl\"]:\n",
    "    for key in dict_motif2TFs.keys():\n",
    "        dict_motif2TFs[key] = [tf.upper() for tf in dict_motif2TFs[key]]\n",
    "\n",
    "elif species in [\"Zebrafish\", \"Xenopus\"]:\n",
    "    for key in dict_motif2TFs.keys():\n",
    "        dict_motif2TFs[key] = [tf.lower() for tf in dict_motif2TFs[key]]\n",
    "\n",
    "elif species in [\"Drosophila\", \"C.elegans\"]:\n",
    "    pass\n",
    "\n",
    "dict_TFs2motif = {}\n",
    "for key, value in dict_motif2TFs.items():\n",
    "    for i in value:\n",
    "        if i not in dict_TFs2motif.keys():\n",
    "            dict_TFs2motif[i] = [key]\n",
    "        else:\n",
    "            dict_TFs2motif[i].append(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to process motif databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gimme_pwm_to_homer(output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for motif_id in motifs:\n",
    "        with open(os.path.join(output_dir, f\"{motif_id.id}.motif\"), 'w') as outfile:\n",
    "                outfile.write(motif_id.to_pwm()[0]+'\\t'+motif_id.to_pwm()[1:]+ '\\n')\n",
    "    return None\n",
    "\n",
    "def split_hocomoco_flat_motifs(input_file, output_dir):\n",
    "    tf=[]\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with open(input_file, 'r') as infile:\n",
    "        motif_name = None\n",
    "        motif_lines = []\n",
    "\n",
    "        for line in infile:\n",
    "            line = line.strip()\n",
    "            \n",
    "            # New motif detected\n",
    "            if line.startswith(\">\"):\n",
    "                # Save previous motif if one exists\n",
    "                if motif_name and motif_lines:\n",
    "                    with open(os.path.join(output_dir, f\"{motif_name}.motif\"), 'w') as outfile:\n",
    "                        outfile.write(\"\\n\".join(motif_lines) + \"\\n\")\n",
    "                \n",
    "                # Start new motif\n",
    "                motif_name = line.split()[1].split('.')[0]\n",
    "                motif_lines = [line]  # Store the header line\n",
    "                tf.append(motif_name)\n",
    "            \n",
    "            else:\n",
    "                motif_lines.append(line)  # Add matrix lines\n",
    "        \n",
    "        # Save last motif in the file\n",
    "        if motif_name and motif_lines:\n",
    "            with open(os.path.join(output_dir, f\"{motif_name}.motif\"), 'w') as outfile:\n",
    "                outfile.write(\"\\n\".join(motif_lines) + \"\\n\")\n",
    "\n",
    "    print(f\"Motifs saved in: {output_dir}\")\n",
    "    return tf\n",
    "\n",
    "def split_meme_flat_motifs(input_file, output_dir):\n",
    "    tf=[]\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with open(input_file, 'r') as infile:\n",
    "        motif_name = None\n",
    "        read_matrix = False\n",
    "        motif_lines = []\n",
    "        for line in infile:\n",
    "            line = line.strip()\n",
    "            # New motif detected\n",
    "            if line.startswith(\"MOTIF\"):\n",
    "                motif_name = line.split()[2]\n",
    "                if '/' in motif_name:\n",
    "                    motif_name = None\n",
    "                else:\n",
    "                    tf.append(motif_name)\n",
    "            # Start reading the matrix\n",
    "            elif (motif_name is not None) and (line.startswith(\"letter-probability matrix\")):\n",
    "                read_matrix = True  # Start reading matrix\n",
    "            # If matrix reading is active, write the lines\n",
    "            elif (motif_name is not None) and read_matrix and line:\n",
    "                motif_lines.append(line)  # Add matrix lines\n",
    "            # Stop reading when an empty line is encountered\n",
    "            elif (motif_name is not None) and read_matrix and line == \"\":\n",
    "                with open(os.path.join(output_dir, f\"{motif_name}.motif\"), 'w') as outfile:\n",
    "                    outfile.write(f\">\\t{motif_name}\\n\")  # Motif header\n",
    "                    outfile.write(\"\\n\".join(motif_lines) + \"\\n\")\n",
    "                read_matrix = False  # Stop reading\n",
    "                motif_name = None  # Reset motif name\n",
    "                motif_lines = []\n",
    "    return tf\n",
    "\n",
    "def cisbp_to_homer(cisbp_file, outfile, tf):\n",
    "    df = pd.read_csv(cisbp_file, sep=\"\\t\")\n",
    "    if \"Pos\" in df.columns:\n",
    "        df = df.iloc[:, 1:]  # Keep only A, C, G, T columns\n",
    "\n",
    "    outfile.write(f\">\\t{tf}\\n\")  # Motif header\n",
    "    df.to_csv(outfile, sep=\" \", index=False, header=False, float_format=\"%.6f\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to write the concatenated pwm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 78\n"
     ]
    }
   ],
   "source": [
    "flatten_hocomoco = False\n",
    "flatten_meme = True\n",
    "write_gimme = True\n",
    "# Reading motif files\n",
    "motif_cluster = pd.read_csv(f'{wd}/out_data/out_other_methods/motifs/jaspar/jaspar2024_motif_cluster_annotations.csv')\n",
    "motif_cluster[['Motif','ID','Name']] = motif_cluster['Motif'].str.split('_', expand=True)\n",
    "motif_cluster[['Cluster','cluster_number']] = motif_cluster['cluster_number'].str.split('_', expand=True)\n",
    "motif_cluster = motif_cluster[['ID','Name','cluster_number']]\n",
    "#'TF_Information.txt' contains, for each TF, all directly determined motifs (see below). \n",
    "# If a TF does not have a directly determined motif, this file will also include its best inferred motif.  \n",
    "# 'Best' is defined as the motif(s) obtained from the most similar TF (based on the %ID in the amino acids of its TF) that has a directly determined motif.\n",
    "TF_info_c = pd.read_csv(f\"{wd}/out_data/out_other_methods/motifs/cisbp/Homo_sapiens_2025_03_16_3_27_pm/TF_Information.txt\", sep='\\t')\n",
    "TF_info_c = TF_info_c[TF_info_c['TF_Status']!='N'].reset_index(drop=True) # No motif Available\n",
    "TF_info_m = pd.read_csv(f\"{wd}/out_data/out_other_methods/motifs/cisbp/Mus_musculus_2025_03_16_4_09_pm/TF_Information.txt\", sep='\\t')\n",
    "TF_info_m = TF_info_m[TF_info_m['TF_Status']!='N'].reset_index(drop=True) # No motif Available\n",
    "\n",
    "TF_info_l = pd.read_csv(f\"{wd}/out_data/out_other_methods/motifs/CRC_lin_lab/MotifDictionary.txt\", sep='\\t', header=None)\n",
    "if write_gimme:\n",
    "    save_gimme_pwm_to_homer(f\"{wd}/out_data/out_other_methods/motifs/gimme/pwm_all_motifs\")\n",
    "\n",
    "if flatten_hocomoco:\n",
    "    TF_info_h = split_hocomoco_flat_motifs( f\"{wd}/out_data/out_other_methods/motifs/hocomoco/H13CORE_homer_format_0.001.motif\", \\\n",
    "                                f\"{wd}/out_data/out_other_methods/motifs/hocomoco/H13CORE_homer_format_0.001/pwm_all_motifs\")\n",
    "else:\n",
    "    TF_info_h = []\n",
    "    with open(f\"{wd}/out_data/out_other_methods/motifs/hocomoco/H13CORE_homer_format_0.001.motif\", \"r\") as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\">\"):\n",
    "                match = re.search(r'([A-Z0-9]+)\\.', line)\n",
    "                if match:\n",
    "                    TF_info_h.append(match.group(1))\n",
    "if flatten_meme:\n",
    "    TF_info_l = split_meme_flat_motifs( f\"{wd}/out_data/out_other_methods/motifs/CRC_lin_lab/VertebratePWMs.txt\", \\\n",
    "                            f\"{wd}/out_data/out_other_methods/motifs/CRC_lin_lab/pwm_all_motifs\")\n",
    "else:\n",
    "    TF_info_l =[]\n",
    "    with open(f\"{wd}/out_data/out_other_methods/motifs/CRC_lin_lab/VertebratePWMs.txt\", \"r\") as file:\n",
    "        if line.startswith(\"MOTIF\"):\n",
    "            motif_name = line.split()[2]\n",
    "            if '/' in motif_name:\n",
    "                TF_info_l.append(motif_name)\n",
    "\n",
    "# with open(f\"{wd}/out_data/co_analysis_1/intermediate_data/TF_to_TG_dictionary.pkl\", 'rb') as f:\n",
    "#     TF_to_TG_dict = pickle.load(f)\n",
    "\n",
    "no_tf_motif, tf_motif = [], {}\n",
    "output_file = f\"{out_path}/out_files/concatenated_pwm.txt\"\n",
    "with open(output_file, 'w') as outfile:\n",
    "    for tf in total_TFs: #list(TF_to_TG_dict.keys()):\n",
    "\n",
    "        if tf in dict_TFs2motif.keys() and len(dict_TFs2motif[tf])!=0:\n",
    "            for id in dict_TFs2motif[tf]:\n",
    "                file_name_motif = f'{id}.motif'\n",
    "                with open(os.path.join(f'{wd}/out_data/out_other_methods/motifs/gimme/pwm_all_motifs/{file_name_motif}'), 'r') as infile:\n",
    "                    outfile.write(infile.read())\n",
    "            tf_motif[tf] = dict_TFs2motif[tf]\n",
    "\n",
    "        elif tf.capitalize() in dict_TFs2motif.keys() and len(dict_TFs2motif[tf.capitalize()])!=0: #Gimme_Mus\n",
    "            for id in dict_TFs2motif[tf.capitalize()]:\n",
    "                file_name_motif = f'{id}.motif'\n",
    "                with open(os.path.join(f'{wd}/out_data/out_other_methods/motifs/gimme/pwm_all_motifs/{file_name_motif}'), 'r') as infile:\n",
    "                    outfile.write(infile.read())\n",
    "            tf_motif[tf] = dict_TFs2motif[tf.capitalize()]\n",
    "\n",
    "        elif tf in dict_TFs2motif.keys() and len(dict_TFs2motif[tf])!=0:\n",
    "            for id in dict_TFs2motif[tf]:\n",
    "                file_name_motif = f'{id}.motif'\n",
    "                with open(os.path.join(f'{wd}/out_data/out_other_methods/motifs/gimme/pwm_all_motifs/{file_name_motif}'), 'r') as infile:\n",
    "                    outfile.write(infile.read())\n",
    "            tf_motif[tf] = dict_TFs2motif[tf]\n",
    "\n",
    "        elif tf.capitalize() in dict_TFs2motif.keys() and len(dict_TFs2motif[tf.capitalize()])!=0: #Gimme_Mus\n",
    "            for id in dict_TFs2motif[tf.capitalize()]:\n",
    "                file_name_motif = f'{id}.motif'\n",
    "                with open(os.path.join(f'{wd}/out_data/out_other_methods/motifs/gimme/pwm_all_motifs/{file_name_motif}'), 'r') as infile:\n",
    "                    outfile.write(infile.read())\n",
    "            tf_motif[tf] = dict_TFs2motif[tf.capitalize()]\n",
    "\n",
    "        elif tf in list(motif_cluster['Name'].str.upper()): #JASPAR-homer\n",
    "            location = np.where(tf==motif_cluster['Name'].str.upper().values)[0][0]\n",
    "            file_name_motif = motif_cluster.loc[location]['Name']+'.'+motif_cluster.loc[location]['ID']+'.motif'\n",
    "            with open(os.path.join(f'{wd}/out_data/out_other_methods/motifs/jaspar/JASPAR2024_CORE_vertebrates_non-redundant_homer/{file_name_motif}'), 'r') as infile:\n",
    "                outfile.write(infile.read())\n",
    "            tf_motif[tf] = motif_cluster.loc[location]['Name']\n",
    "\n",
    "        elif tf in list(TF_info_c['TF_Name'].str.upper()): #CISBP\n",
    "            location = np.where(tf==TF_info_c['TF_Name'].str.upper().values)[0][0]\n",
    "            file_name_motif = TF_info_c.loc[location]['Motif_ID']+'.txt'\n",
    "            cisbp_file = os.path.join(f'{wd}/out_data/out_other_methods/motifs/cisbp/Homo_sapiens_2025_03_16_3_27_pm/pwms_all_motifs/{file_name_motif}')\n",
    "            cisbp_to_homer(cisbp_file, outfile,TF_info_c.loc[location]['TF_Name'])\n",
    "            tf_motif[tf] = TF_info_c.loc[location]['TF_Name']\n",
    "\n",
    "        elif tf in pd.Series(TF_info_h).str.upper().values: #HOCOMOCO-homer\n",
    "            location = np.where(tf==pd.Series(TF_info_h).str.upper().values)[0][0]\n",
    "            file_name_motif = TF_info_h[location]+'.motif'\n",
    "            with open(os.path.join(f\"{wd}/out_data/out_other_methods/motifs/hocomoco/H13CORE_homer_format_0.001/pwm_all_motifs/{file_name_motif}\"), 'r') as infile:\n",
    "                outfile.write(infile.read())\n",
    "            tf_motif[tf] = TF_info_h[location]\n",
    "\n",
    "        elif tf in pd.Series(TF_info_l).str.upper().values: #LinLab-meme\n",
    "            location = np.where(tf==pd.Series(TF_info_l).str.upper().values)[0][0]\n",
    "            file_name_motif = TF_info_l[location]+'.motif'\n",
    "            with open(os.path.join(f\"{wd}/out_data/out_other_methods/motifs/CRC_lin_lab/pwm_all_motifs/{file_name_motif}\"), 'r') as infile:\n",
    "                outfile.write(infile.read())\n",
    "            tf_motif[tf] = TF_info_l[location]\n",
    "\n",
    "        elif tf in list(TF_info_m['TF_Name'].str.upper()): #CISBP_Mus\n",
    "            location = np.where(tf==TF_info_m['TF_Name'].str.upper().values)[0][0]\n",
    "            file_name_motif = TF_info_m.loc[location]['Motif_ID']+'.txt'\n",
    "            cisbp_file = os.path.join(f'{wd}/out_data/out_other_methods/motifs/cisbp/Mus_musculus_2025_03_16_4_09_pm/pwms_all_motifs/{file_name_motif}')\n",
    "            cisbp_to_homer(cisbp_file, outfile, TF_info_m.loc[location]['TF_Name'])\n",
    "            tf_motif[tf] = TF_info_m.loc[location]['TF_Name']\n",
    "\n",
    "        else:\n",
    "            no_tf_motif.append(tf)\n",
    "print(len(no_tf_motif), len(tf_motif))\n",
    "# with open(f\"{out_path}/out_files/tf_motif.pkl\", 'wb') as f:\n",
    "#     pickle.dump(tf_motif, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
